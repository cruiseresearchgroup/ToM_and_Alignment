{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "import json \n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.metrics import accuracy_score\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['GOOGLE_API_KEY'] = 'AIzaSyCAdly9ydzMLU0JicI3Nzmg3d81Ap8UBYI'\n",
    "os.environ['AIML_API_KEY'] = 'cd610f9c790e4905a55a4f97182e72eb'\n",
    "os.environ['NVIDIA_API_KEY'] = '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'\n",
    "os.environ['OPENAI_API_KEY'] = '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'\n",
    "os.environ['PYTHONUNBUFFERED'] = '1'\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "plain_prompt = '''\n",
    "**Task Description:**  \n",
    "You are an expert in linguistics.  \n",
    "Two individuals are negotiating how to divide various items for a picnic.  \n",
    "A selected statement from the dialogue will be replicated by two language models.  \n",
    "You need to determine which of the candidate statements more effectively captures the actual response.  \n",
    "Consider the gramatical coherency, intention behind the utterance, as well as each person's beliefs about the other and their own desire to share.  \n",
    "The sample is as follows: \n",
    "Actual: &&\n",
    "Candidate 1: $$\n",
    "Candidate 2: ##\n",
    "\n",
    "\n",
    "Answer with the candidate number just `1` or `2`.\n",
    "'''\n",
    "\n",
    "main_LLM_role = '''\n",
    "**Task Description:**  \n",
    "You are an expert in linguistics.  \n",
    "Two individuals are negotiating how to divide various items for a picnic.  \n",
    "A selected statement from the dialogue will be replicated by two language models.  \n",
    "You need to determine which of the candidate statements more effectively captures the actual response.  \n",
    "Consider the gramatical coherency, intention behind the utterance, as well as each person's beliefs about the other and their own desire to share.  \n",
    "Answer with one of [Candidate 1 or Candidate 2] => [The reasoning behind your choice], you can not answer with a neither.\n",
    "\n",
    "'''.strip()\n",
    "\n",
    "question1 = '''\n",
    "Actual: Hello! Which item do you need the most?\n",
    "Candidate 1: Hello! I would need extra food for the trip.\n",
    "Candidate 2: Hey hey, just need to know what is essential for you.\n",
    "'''.strip()\n",
    "\n",
    "answer1 = '''Candidate 2 => Because it reflects the intention of the actual response more closely, which is an inquiry about the other's need'''.strip()\n",
    "\n",
    "question2 = '''\n",
    "Actual: If you care more about the fuel for your car, I can grab a gallon for you.\n",
    "Candidate 2: For me, it works, but I would share my food with you. \n",
    "Candidate 1: I will bring some spare gasoline just in case. \n",
    "'''.strip()\n",
    "\n",
    "answer2 = '''Candidate 1 => Because it truly identified the other parties need which is extra fuel'''.strip()\n",
    "\n",
    "question3 = '''\n",
    "Actual: As I suffer from diabetes I need to have my medicine with me all the time. \n",
    "Candidate 2: I can hike with you as long as my medicine is safe and accessible to me\n",
    "Candidate 1: would you have any spare space in the trunk?\n",
    "'''.strip()\n",
    "\n",
    "answer3 = '''Candidate 2 => Because it clarifies the speaker's need for medicine, similar to the actual response'''.strip()\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": main_LLM_role},\n",
    "    {\"role\": \"user\", \"content\": question1},\n",
    "    {\"role\": \"assistant\", \"content\": answer1},\n",
    "    {\"role\": \"user\", \"content\": question2},\n",
    "    {\"role\": \"assistant\", \"content\": answer2},\n",
    "    {\"role\": \"user\", \"content\": question3},\n",
    "    {\"role\": \"assistant\", \"content\": answer3},\n",
    "\n",
    "]\n",
    "# print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLM_google:\n",
    "    def __init__(self, model=\"gemini-1.5-flash\"): # gpt-4o\n",
    "        self.model = model\n",
    "        self.messages = messages\n",
    "        self.client = OpenAI(\n",
    "            base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\",\n",
    "            api_key=os.environ.get(\"GOOGLE_API_KEY\"),\n",
    "        )\n",
    "        \n",
    "    def generate(self, query, n=1):\n",
    "        sleep(2)\n",
    "        try:\n",
    "            temp = {\"role\": \"user\", \"content\": query}\n",
    "            chat_completion = self.client.chat.completions.create(messages=self.messages+[temp], model=self.model, top_p=1e-9,\n",
    "                                                                n=n)\n",
    "            if n==1:\n",
    "                response = chat_completion.to_dict()['choices'][0]['message']['content']\n",
    "            if n>1:\n",
    "                response = [chat_completion.to_dict()['choices'][idx]['message']['content'] for idx in range(n)]\n",
    "        \n",
    "            return response\n",
    "        except:\n",
    "            print('google')\n",
    "            return None\n",
    "class Reasoner_openai:\n",
    "    def __init__(self, model=\"gpt-4o\"): # gpt-4o\n",
    "        self.model = model\n",
    "        self.messages = plain_prompt\n",
    "        self.client = OpenAI(\n",
    "            api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "        )\n",
    "        \n",
    "    def generate(self, query, n=1):\n",
    "        try:\n",
    "            chat_completion = self.client.chat.completions.create(messages=query, model=self.model,\n",
    "                                                                seed=42, n=n)\n",
    "            if n==1:\n",
    "                response = chat_completion.to_dict()['choices'][0]['message']['content']\n",
    "            if n>1:\n",
    "                response = [chat_completion.to_dict()['choices'][idx]['message']['content'] for idx in range(n)]\n",
    "            return response\n",
    "        except:\n",
    "            print('Reasoner')\n",
    "            return None\n",
    "class LLM_openai:\n",
    "    def __init__(self, model=\"gpt-4o\"): # gpt-4o\n",
    "        self.model = model\n",
    "        self.messages = messages\n",
    "        self.client = OpenAI(\n",
    "            api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "        )\n",
    "        \n",
    "    def generate(self, query, n=1):\n",
    "        try:\n",
    "            temp = {\"role\": \"user\", \"content\": query}\n",
    "            chat_completion = self.client.chat.completions.create(messages=self.messages+[temp], model=self.model, top_p=1e-9,\n",
    "                                                                seed=42, n=n)\n",
    "            if n==1:\n",
    "                response = chat_completion.to_dict()['choices'][0]['message']['content']\n",
    "            if n>1:\n",
    "                response = [chat_completion.to_dict()['choices'][idx]['message']['content'] for idx in range(n)]\n",
    "        \n",
    "            return response\n",
    "        except:\n",
    "            print('openai')\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_winrate(path, model1, model2, model3, sample_size=None):\n",
    "    output_file = path.replace('steer_files', 'winrate').replace('.jsonl', '.xlsx')\n",
    "    # print(output_file)\n",
    "    if os.path.exists(output_file):\n",
    "        df = pd.read_excel(output_file)\n",
    "    else:\n",
    "        with open(path, 'r') as fin:\n",
    "            data = json.load(fin)\n",
    "        llm1 = Reasoner_openai(model1)\n",
    "        llm2 = LLM_openai(model2)\n",
    "        llm3 = LLM_google(model3)\n",
    "        aligned = 0\n",
    "        result = {\n",
    "            'Aligned':[],\n",
    "            'Non-aligned':[],\n",
    "            'Ground-truth':[],\n",
    "            'Actual':[], \n",
    "            'M1-response':[],\n",
    "            'M2-response':[],\n",
    "            'M3-response':[],\n",
    "        }\n",
    "        ss = sample_size if sample_size!=None else len(data)\n",
    "        for i in tqdm(range(ss)):\n",
    "            \n",
    "            a = data[i]['aligned_respons']\n",
    "            na = data[i]['nonaligned_resopnse']\n",
    "            gt = data[i]['golden_response']\n",
    "            result['Aligned'].append(a)\n",
    "            result['Non-aligned'].append(na)\n",
    "            result['Ground-truth'].append(gt)\n",
    "            aligned = (1-aligned)\n",
    "            result['Actual'].append(aligned)\n",
    "            if aligned==0:\n",
    "                temp = plain_prompt.replace('&&', a).replace('$$', a).replace('##', na)\n",
    "                # print(temp)\n",
    "                llm1_response = llm1.generate(query=[{'role':'user', 'content':temp}])\n",
    "                llm2_response = llm2.generate(query=f\"Actual: {gt}\\nCandidate 1: {a}\\nCandidate 2: {na}\")\n",
    "                llm3_response = llm3.generate(query=f\"Actual:{gt}\\nCandidate 1: {a}\\nCandidate 2: {na}\")\n",
    "            if aligned==1:\n",
    "                temp = plain_prompt.replace('&&', gt).replace('$$', na).replace('##', a)\n",
    "                # print(temp)\n",
    "                llm1_response = llm1.generate(query=[{'role':'user', 'content':temp}])\n",
    "                llm2_response = llm2.generate(query=f\"Actual: {gt}\\nCandidate 1: {na}\\nCandidate 2: {a}\")\n",
    "                llm3_response = llm3.generate(query=f\"Actual: {gt}\\nCandidate 1: {na}\\nCandidate 2: {a}\")\n",
    "            try:\n",
    "                response = int(llm1_response.strip())-1\n",
    "            except:\n",
    "                response = None\n",
    "                print(llm1_response)\n",
    "            result['M1-response'].append(response)\n",
    "            try:\n",
    "                response = int(llm2_response.strip().split(' ')[1].strip())-1\n",
    "            except:\n",
    "                response = None\n",
    "                print(llm2_response)\n",
    "            result['M2-response'].append(response)\n",
    "            try:\n",
    "                response = int(llm3_response.strip().split(' ')[1].strip())-1\n",
    "            except:\n",
    "                response = None\n",
    "                print(llm3_response)\n",
    "            result['M3-response'].append(response)\n",
    "        df = pd.DataFrame(result)\n",
    "        df['Ensemble-Response'] = df.apply(lambda row: Counter([row['M1-response'], row['M2-response'], row['M3-response']]).most_common(1)[0][0], axis=1)\n",
    "        df['Agreement'] = df.apply(lambda row:1 if ((row['M1-response']==row['M2-response']) and (row['M2-response']==row['M3-response'])) else 0 , axis=1)\n",
    "        df.to_excel(output_file, index=False)\n",
    "    print(f'{output_file.split(\"/\")[-1].split(\".\")[0]}: ', 'Win Ratio', round(accuracy_score(df['Actual'].to_list(), df['Ensemble-Response'].fillna(1).to_list()), 2), f'Length = {len(df)}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steering_Belief_Firewood:  Win Ratio 0.53 Length = 133\n",
      "steering_Belief_Food:  Win Ratio 0.72 Length = 163\n",
      "steering_Belief_Water:  Win Ratio 0.73 Length = 189\n",
      "steering_Desire_Firewood:  Win Ratio 0.32 Length = 180\n",
      "steering_Desire_Food:  Win Ratio 0.65 Length = 162\n",
      "steering_Desire_Water:  Win Ratio 0.67 Length = 179\n",
      "steering_Intention_Build-Rapport:  Win Ratio 0.63 Length = 294\n",
      "steering_Intention_Promote-Coordination:  Win Ratio 0.72 Length = 144\n",
      "steering_Intention_Describe-Need:  Win Ratio 0.55 Length = 316\n",
      "steering_Intention_Discover-Preference:  Win Ratio 0.68 Length = 91\n",
      "steering_Intention_Show-Empathy:  Win Ratio 0.51 Length = 89\n"
     ]
    }
   ],
   "source": [
    "get_winrate('out/steer_files/8b/steering_Belief_Firewood.jsonl',\n",
    "            'o1-preview', \n",
    "            'gpt-4o',\n",
    "            'gemini-1.5-pro')\n",
    "get_winrate('out/steer_files/3b/steering_Belief_Food.jsonl',\n",
    "            'o1-preview', \n",
    "            'gpt-4o',\n",
    "            'gemini-1.5-pro')\n",
    "get_winrate('out/steer_files/8b/steering_Belief_Water.jsonl',\n",
    "            'o1-preview', \n",
    "            'gpt-4o',\n",
    "            'gemini-1.5-pro')\n",
    "get_winrate('out/steer_files/8b/steering_Desire_Firewood.jsonl',\n",
    "            'o1-preview', \n",
    "            'gpt-4o',\n",
    "            'gemini-1.5-pro')\n",
    "get_winrate('out/steer_files/8b/steering_Desire_Food.jsonl',\n",
    "            'o1-preview', \n",
    "            'gpt-4o',\n",
    "            'gemini-1.5-pro')\n",
    "get_winrate('out/steer_files/8b/steering_Desire_Water.jsonl',\n",
    "            'o1-preview', \n",
    "            'gpt-4o',\n",
    "            'gemini-1.5-pro')\n",
    "get_winrate('out/steer_files/8b/steering_Intention_Build-Rapport.jsonl',\n",
    "            'o1-preview', \n",
    "            'gpt-4o',\n",
    "            'gemini-1.5-pro')\n",
    "get_winrate('out/winrate/8b/steering_Intention_Promote-Coordination.jsonl',\n",
    "            'o1-preview', \n",
    "            'gpt-4o',\n",
    "            'gemini-1.5-pro')\n",
    "get_winrate('out/steer_files/8b/steering_Intention_Describe-Need.jsonl',\n",
    "            'o1-preview', \n",
    "            'gpt-4o',\n",
    "            'gemini-1.5-pro')\n",
    "get_winrate('out/winrate/8b/steering_Intention_Discover-Preference.jsonl',\n",
    "            'o1-preview', \n",
    "            'gpt-4o',\n",
    "            'gemini-1.5-pro')\n",
    "get_winrate('out/winrate/8b/steering_Intention_Show-Empathy.jsonl',\n",
    "            'o1-preview', \n",
    "            'gpt-4o',\n",
    "            'gemini-1.5-pro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steering_Belief_Firewood:  Win Ratio 0.74 Length = 133\n",
      "steering_Belief_Food:  Win Ratio 0.72 Length = 163\n",
      "steering_Belief_Water:  Win Ratio 0.69 Length = 189\n",
      "steering_Desire_Firewood:  Win Ratio 0.74 Length = 180\n",
      "steering_Desire_Food:  Win Ratio 0.48 Length = 162\n",
      "steering_Desire_Water:  Win Ratio 0.3 Length = 179\n",
      "steering_Intention_Build-Rapport:  Win Ratio 0.73 Length = 294\n",
      "steering_Intention_Promote-Coordination:  Win Ratio 0.8 Length = 144\n",
      "steering_Intention_Describe-Need:  Win Ratio 0.52 Length = 316\n",
      "steering_Intention_Discover-Preference:  Win Ratio 0.57 Length = 91\n",
      "steering_Intention_Show-Empathy:  Win Ratio 0.47 Length = 89\n"
     ]
    }
   ],
   "source": [
    "get_winrate('out/steer_files/3b/steering_Belief_Firewood.jsonl',\n",
    "            'o1-preview', \n",
    "            'gpt-4o',\n",
    "            'gemini-1.5-pro')\n",
    "get_winrate('out/steer_files/3b/steering_Belief_Food.jsonl',\n",
    "            'o1-preview', \n",
    "            'gpt-4o',\n",
    "            'gemini-1.5-pro')\n",
    "get_winrate('out/steer_files/3b/steering_Belief_Water.jsonl',\n",
    "            'o1-preview', \n",
    "            'gpt-4o',\n",
    "            'gemini-1.5-pro')\n",
    "get_winrate('out/steer_files/3b/steering_Desire_Firewood.jsonl',\n",
    "            'o1-preview', \n",
    "            'gpt-4o',\n",
    "            'gemini-1.5-pro')\n",
    "get_winrate('out/steer_files/3b/steering_Desire_Food.jsonl',\n",
    "            'o1-preview', \n",
    "            'gpt-4o',\n",
    "            'gemini-1.5-pro')\n",
    "get_winrate('out/steer_files/3b/steering_Desire_Water.jsonl',\n",
    "            'o1-preview', \n",
    "            'gpt-4o',\n",
    "            'gemini-1.5-pro')\n",
    "get_winrate('out/steer_files/3b/steering_Intention_Build-Rapport.jsonl',\n",
    "            'o1-preview', \n",
    "            'gpt-4o',\n",
    "            'gemini-1.5-pro')\n",
    "get_winrate('out/steer_files/3b/steering_Intention_Promote-Coordination.jsonl',\n",
    "            'o1-preview', \n",
    "            'gpt-4o',\n",
    "            'gemini-1.5-pro')\n",
    "get_winrate('out/steer_files/3b/steering_Intention_Describe-Need.jsonl',\n",
    "            'o1-preview', \n",
    "            'gpt-4o',\n",
    "            'gemini-1.5-pro')\n",
    "get_winrate('out/steer_files/3b/steering_Intention_Discover-Preference.jsonl',\n",
    "            'o1-preview', \n",
    "            'gpt-4o',\n",
    "            'gemini-1.5-pro')\n",
    "get_winrate('out/steer_files/3b/steering_Intention_Show-Empathy.jsonl',\n",
    "            'o1-preview', \n",
    "            'gpt-4o',\n",
    "            'gemini-1.5-pro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "latentqa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
