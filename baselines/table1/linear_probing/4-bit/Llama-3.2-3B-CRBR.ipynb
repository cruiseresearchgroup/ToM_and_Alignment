{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('./src')\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.CRAIGSLISTBARGAIN import *\n",
    "from src.dataset import SimpleTextDataset\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from dataset import TextDataset \n",
    "\n",
    "import time\n",
    "\n",
    "# from CaSiNo import *\n",
    "from common import *\n",
    "\n",
    "tic, toc = (time.time, time.time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n",
      "`low_cpu_mem_usage` was None, now default to True since model is quantized.\n",
      "You shouldn't move a model that is dispatched using accelerate hooks.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"unsloth/Llama-3.2-3B-Instruct-unsloth-bnb-4bit\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"unsloth/Llama-3.2-3B-Instruct-unsloth-bnb-4bit\")\n",
    "model.cuda();\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = fetch_and_prepare_dataset('./dataset/CRAIGSLISTBARGAIN/train.json')\n",
    "# valid = fetch_and_prepare_dataset('./dataset/CRAIGSLISTBARGAIN/valid.json')\n",
    "valid = fetch_and_prepare_dataset('./dataset/CRAIGSLISTBARGAIN/test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['quintile'] = pd.qcut(train['buyer_price'], q=20, labels=[int(i) for i in range(1, 21)])\n",
    "train_dialogs = train[(train.chat_log.apply(lambda item:len(item)>8))&(train['quintile']<18)].apply(lambda row: causal_dialogue_merge(row, ), axis=1).to_list()\n",
    "valid_dialogs = valid[(valid.chat_log.apply(lambda item:len(item)>8))&(valid['buyer_price']<2450)].apply(lambda row: causal_dialogue_merge(row, ), axis=1).to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5401b0bc69042039731391471702dd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2643 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "870a403976c04a19a50de0ce51812be1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/429 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train = [(item['hidden_states'][5], item['hidden_states'][15], item['hidden_states'][25]) for item in SimpleTextDataset(train_dialogs, tokenizer=tokenizer, model=model, residual_stream=True)]\n",
    "y_train = train[(train.chat_log.apply(lambda item:len(item)>8))&(train['quintile']<18)]['buyer_price'].to_list()\n",
    "\n",
    "X_valid = [(item['hidden_states'][5], item['hidden_states'][15], item['hidden_states'][25]) for item in SimpleTextDataset(valid_dialogs, tokenizer=tokenizer, model=model, residual_stream=True)]\n",
    "y_valid = valid[(valid.chat_log.apply(lambda item:len(item)>8))&(valid['buyer_price']<2450)]['buyer_price'].to_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the layer 5 R^2 score for the buyer_price: 0.35\n",
      "For the layer 15 R^2 score for the buyer_price: 0.27\n",
      "For the layer 25 R^2 score for the buyer_price: 0.57\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "            'pca__n_components': [n for n in range(0, 500, 100)],\n",
    "            'regressor__alpha': [0],\n",
    "        }\n",
    "for layer in range(3):\n",
    "    X = [item[layer].squeeze().numpy() for item in X_train]\n",
    "    scaler = StandardScaler()\n",
    "    transformed_y = scaler.fit_transform(np.array(y_train).reshape(-1, 1))\n",
    "    best_estimator_, best_score_, gs_best_params = fit_ridge_regression_pipeline(X, transformed_y, param_grid=param_grid)\n",
    "    XT = [item[layer].squeeze().numpy() for item in X_valid]\n",
    "    pred = best_estimator_.predict(XT)\n",
    "    scaled_pred = scaler.inverse_transform(pred)\n",
    "    base_r2 = r2_score(y_valid, scaled_pred)\n",
    "    print(f'For the layer {[5, 15, 25][layer]} R^2 score for the buyer_price: {round(base_r2, 2)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = fetch_and_prepare_dataset('./dataset/CRAIGSLISTBARGAIN/train.json')\n",
    "# valid = fetch_and_prepare_dataset('./dataset/CRAIGSLISTBARGAIN/valid.json')\n",
    "valid = fetch_and_prepare_dataset('./dataset/CRAIGSLISTBARGAIN/test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['quintile'] = pd.qcut(train['seller_price'], q=20, labels=[int(i) for i in range(1, 21)])\n",
    "train_dialogs = train[(train.chat_log.apply(lambda item:len(item)>8))&(train['quintile']<18)].apply(lambda row: causal_dialogue_merge(row, ), axis=1).to_list()\n",
    "valid_dialogs = valid[(valid.chat_log.apply(lambda item:len(item)>8))&(valid['seller_price']<3400)].apply(lambda row: causal_dialogue_merge(row, ), axis=1).to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98fb6fe8e42f4a12aede0c5605342494",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2630 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e250a140a11141ac969dfc887a7e1ffb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/424 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train = [(item['hidden_states'][5], item['hidden_states'][15], item['hidden_states'][25]) for item in SimpleTextDataset(train_dialogs, tokenizer=tokenizer, model=model, residual_stream=True)]\n",
    "y_train = train[(train.chat_log.apply(lambda item:len(item)>8))&(train['quintile']<18)]['seller_price'].to_list()\n",
    "\n",
    "X_valid = [(item['hidden_states'][5], item['hidden_states'][15], item['hidden_states'][25]) for item in SimpleTextDataset(valid_dialogs, tokenizer=tokenizer, model=model, residual_stream=True)]\n",
    "y_valid = valid[(valid.chat_log.apply(lambda item:len(item)>8))&(valid['seller_price']<3400)]['seller_price'].to_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the layer 5 R^2 score for the Seller_price: 0.36\n",
      "For the layer 15 R^2 score for the Seller_price: 0.19\n",
      "For the layer 25 R^2 score for the Seller_price: 0.54\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "            'pca__n_components': [n for n in range(0, 500, 100)],\n",
    "            'regressor__alpha': [0],\n",
    "        }\n",
    "for layer in range(3):\n",
    "    X = [item[layer].squeeze().numpy() for item in X_train]\n",
    "    scaler = StandardScaler()\n",
    "    transformed_y = scaler.fit_transform(np.array(y_train).reshape(-1, 1))\n",
    "    best_estimator_, best_score_, gs_best_params = fit_ridge_regression_pipeline(X, transformed_y, param_grid=param_grid)\n",
    "    XT = [item[layer].squeeze().numpy() for item in X_valid]\n",
    "    pred = best_estimator_.predict(XT)\n",
    "    scaled_pred = scaler.inverse_transform(pred)\n",
    "    base_r2 = r2_score(y_valid, scaled_pred)\n",
    "    print(f'For the layer {[5, 15, 25][layer]} R^2 score for the Seller_price: {round(base_r2, 2)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs_exp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
